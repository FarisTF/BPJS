{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "1. [Data Preparation](#dprep)\n",
    "2. [Exploratory Data Analysis](#expda)\n",
    "5. [Feature Engineering](#fe)\n",
    "4. [Data Cleansing](#dclean)\n",
    "5. [Modeling](#model)\n",
    "6. [Evaluation](#eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation <a name=\"dprep\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import seluruh library yang diperlukan\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from datetime import datetime\n",
    "from imblearn.over_sampling import RandomOverSampler \n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "def load_data(main_path, diag_path, proc_path):\n",
    "    main = pd.read_csv(main_path)\n",
    "    diag = pd.read_csv(diag_path)\n",
    "    proc = pd.read_csv(proc_path)\n",
    "\n",
    "    return main, diag, proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main, df_diag, df_proc = load_data('sampling_healtkathon2022/sampling_healtkathon2022.csv', \n",
    "                                    'sampling_healthkathon2022_diagnosa/sampling_healthkathon2022_diagnosa.csv', \n",
    "                                    'sampling_healthkathon2022_procedure/sampling_healthkathon2022_procedure.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis <a name=\"expda\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mencari persebaran 0 dan 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dist = df_main.groupby('label').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(['0','1'],label_dist, align='center', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mencari jumlah NA di setiap kolom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_main = df_main.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering <a name=\"fe\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ngambil occuring\n",
    "\n",
    "def merge_main_diag_proc(main, diag, proc):\n",
    "    # Occur Diagnosa\n",
    "    occur = pd.DataFrame()\n",
    "    occur = occur.assign(occur_diagnosis = diag.groupby('id').size()) \n",
    "    gabungan_diag = main.merge(occur, on='id', how='left')\n",
    "\n",
    "    # Occur Procedure\n",
    "    occur = pd.DataFrame()\n",
    "    occur = occur.assign(occur_procedure = proc.groupby('id').size()) \n",
    "    gabungan_final = gabungan_diag.merge(occur, on='id', how='left')\n",
    "    \n",
    "    return gabungan_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = merge_main_diag_proc(df_main,df_diag,df_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns (merged):\n",
    "    merged = merged.drop(columns=['id'])\n",
    "    merged = merged.drop(columns=['id_peserta'])\n",
    "    merged['biaya_bagi100'] = merged['biaya']/100\n",
    "    merged = merged.drop(columns=['biaya'])\n",
    "\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dropped = drop_columns(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menghitung selisih antar tanggal\n",
    "\n",
    "def days_between(d1, d2):\n",
    "    d1 = datetime.strptime(d1, \"%Y-%m-%d\")\n",
    "    d2 = datetime.strptime(d2, \"%Y-%m-%d\")\n",
    "    return abs((d2 - d1).days)\n",
    "\n",
    "def process_difference (merged_dropped):\n",
    "    merged_dropped[\"Selisih\"] = \" \"\n",
    "\n",
    "    for i in range(len(merged_dropped)) :\n",
    "        \n",
    "        x = merged_dropped.iloc[i]['tgldatang']\n",
    "        y = merged_dropped.iloc[i]['tglpulang']\n",
    "\n",
    "        if x == y :\n",
    "            merged_dropped.at[i,'Selisih'] = 0\n",
    "\n",
    "        else :\n",
    "\n",
    "            TanggalX = x[0:10]\n",
    "            TanggalY = y[0:10]\n",
    "\n",
    "            Selisih = days_between(TanggalX, TanggalY)\n",
    "            merged_dropped.at[i, 'Selisih'] = Selisih\n",
    "\n",
    "    merged_dropped = merged_dropped.drop(columns=['tgldatang'])\n",
    "    merged_dropped = merged_dropped.drop(columns=['tglpulang'])\n",
    "\n",
    "    return merged_dropped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_selisih = process_difference(merged_dropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Cleansing <a name=\"dclean\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_na(no_na):\n",
    "    no_na['jenkel'] = no_na['jenkel'].fillna(no_na['jenkel'].mode()[0])\n",
    "    no_na['pisat'] = no_na['pisat'].fillna(no_na['pisat'].mode()[0])\n",
    "    no_na['diagfktp'] = no_na['diagfktp'].fillna(no_na['diagfktp'].mode()[0])\n",
    "    no_na['jenispulang'] = no_na['jenispulang'].fillna(no_na['jenispulang'].mode()[0])\n",
    "    no_na['occur_procedure'] = no_na['occur_procedure'].fillna(0)\n",
    "    no_na['occur_procedure'] = no_na['occur_procedure'].fillna(0)\n",
    "\n",
    "\n",
    "    no_na['politujuan'] = no_na['politujuan'].fillna('ZZZ')\n",
    "    no_na['kdsa'] = no_na['kdsa'].fillna('ZZZ')\n",
    "    no_na['kdsp'] = no_na['kdsp'].fillna('ZZZZ')\n",
    "    no_na['kdsr'] = no_na['kdsr'].fillna('ZZZZZ')\n",
    "    no_na['kdsi'] = no_na['kdsi'].fillna('ZZZZZZ')\n",
    "    no_na['kdsd'] = no_na['kdsd'].fillna('ZZZZZZZ')\n",
    "\n",
    "    return no_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanril = process_na(with_selisih)\n",
    "\n",
    "cleanril"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanril.to_csv('clean_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== CHECKPOINT ====================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from datetime import datetime\n",
    "from imblearn.over_sampling import RandomOverSampler \n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "clean = pd.read_csv('clean_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred = clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pembuatan data training\n",
    "def convert_to_train(clean):\n",
    "    satufull = clean.loc[clean['label'] == 1] # Pengambilan yang labelnya 1\n",
    "    nolfull = clean.loc[clean['label'] == 0] # Pengambilan yang label 0\n",
    "\n",
    "    jumsat = int(len(satufull))\n",
    "    jumnol = int(len(nolfull)/3)\n",
    "    satu = satufull.sample(n=(jumsat))\n",
    "    nol = nolfull.sample(n=(jumnol)) # Pengambilan label 0 sejumlah banyaknya label 1\n",
    "\n",
    "    Train = nol.append(satu)\n",
    "    Train = Train.sample(frac = 1)\n",
    "\n",
    "    X = Train.drop(columns=['label'])\n",
    "    y = Train.label\n",
    "\n",
    "    X_train_pre, X_test, y_train_pre, y_test = train_test_split(X, y,stratify=y, test_size=0.01, random_state=42)\n",
    "\n",
    "    oversample = RandomOverSampler(sampling_strategy=0.08)\n",
    "\n",
    "    X_train, y_train = oversample.fit_resample(X_train_pre, y_train_pre)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = convert_to_train(clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modeling <a name=\"model\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fitting(X_train, X_test, y_train, y_test):\n",
    "    catboost_model = CatBoostClassifier(n_estimators=700,\n",
    "                        loss_function='CrossEntropy',\n",
    "                        learning_rate=0.4375,\n",
    "                        depth=4, task_type='GPU',\n",
    "                        random_state=1,\n",
    "                        verbose=False)\n",
    "\n",
    "    pool_train = Pool(X_train, y_train,\n",
    "                    cat_features = ['typefaskes', 'jenkel', 'politujuan', 'diagfktp', 'cbg', 'kdsa', 'kdsp', 'kdsr', 'kdsi', 'kdsd'])\n",
    "                    \n",
    "    pool_test = Pool(X_test, cat_features = ['typefaskes', 'jenkel', 'politujuan', 'diagfktp', 'cbg', 'kdsa', 'kdsp', 'kdsr', 'kdsi', 'kdsd'])\n",
    "\n",
    "    catboost_model.fit(pool_train)\n",
    "    y_pred = catboost_model.predict(pool_test)\n",
    "    cb_rmse = np.sqrt(mse(y_test, y_pred))\n",
    "    print(\"RMSE:\", np.mean(cb_rmse))\n",
    "\n",
    "    return catboost_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_model = model_fitting(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "Hasilpred = catboost_model.predict(Pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation <a name=\"eval\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "def evaluate(clean, Hasilpred):\n",
    "    y_true = clean.label\n",
    "    y_pred = Hasilpred  # List of your dataframes\n",
    "\n",
    "\n",
    "    def check(true,pred)  :\n",
    "        tn, fp, fn, tp = confusion_matrix(true, pred).ravel()\n",
    "        Accuracy = (tn+tp) / (tn+fp+tp+fn)\n",
    "        Precision = tp/(tp+fp)\n",
    "        Recall = tp/(tp+fn)\n",
    "        Specifity = tn/(tn+fp)  \n",
    "\n",
    "        print(\"Accuracy    :\", Accuracy, \"\\nPrecision   :\", Precision, \"\\nRecall      :\", Recall, \"\\nSpecifity   :\", Specifity)\n",
    "\n",
    "    check(y_true,y_pred)\n",
    "\n",
    "    print(\"ROC AUC     :\", roc_auc_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(clean, Hasilpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================== START NEW CSV ===================\n",
    "\n",
    "def pipeline_pred(main_path, diag_path, proc_path):\n",
    "    df_main, df_diag, df_proc = load_data(main_path, diag_path, proc_path)\n",
    "    df_merged = merge_main_diag_proc(df_main,df_diag,df_proc)\n",
    "    merged_dropped = drop_columns(df_merged)\n",
    "    with_selisih = process_difference(merged_dropped)\n",
    "    pred = process_na(with_selisih)\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_real = pipeline_pred('Pred/sampling2_healthkathon2022_sep.csv', \n",
    "                            'Pred/sampling2_healthkathon2022_diagnosa.csv',\n",
    "                            'Pred/sampling2_healthkathon_2022_procedure.csv')\n",
    "pred_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_real.to_csv('pred_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasil_pred = catboost_model.predict(pred_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = pd.read_csv('Pred/sampling2_healthkathon2022_sep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = pd.DataFrame()\n",
    "answer['id']= original['id']\n",
    "answer['label'] = hasil_pred\n",
    "\n",
    "print(answer)\n",
    "\n",
    "# Save ke csv\n",
    "answer.to_csv('answer.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4a0531abcd9c922ceff5672ccd49a3b8884c2b6be504a35d6a99f045b5353c84"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
